# 👌大促产生的一次内存泄漏问题排查

[此处为语雀卡片，点击链接查看](https://www.yuque.com/jingdianjichi/xyxdsi/puxcyvwhgd1f1sv6#scSVU)

这道题是在大促的时候产生的一次内存泄漏问题，给大家进行一波讲解和排查。这样当面试官问你内存泄漏问题有没有排查过的时候，你就可以咔咔乱杀了！

本排查案例是通用的！大家消化完成，直接套到自己项目即可！

<font style="color:#DF2A3F;">本题配备了视频助于理解。</font>

## 背景
马上临近大促（你们可以说某天收到了一个内存占用过高的一个报警），对于一些机器的各种报警特别敏感，晚上收到其中一个应用几条内存占用过高的报警，打开监控界面及历史消息发现该应用最近频繁内存报警，采用命令进行fullGC也并不能回收内存，目前采用重启应用解决该报警问题，为了从根本上解决问题，所以决定查一下具体原因。

## 现象：
经观察和分析，发现该应用有以下主要症状：

### 1、内存趋势
内存在使用高峰期（8:00-20:00）增长较快，在低峰期增长较慢，半夜睡觉无什么增长。

### 2、线程数趋势
应用JVM监控中的线程数持续增长，同时，使用高峰期（8:00-20:00）增长较快，在低峰期增长较慢。

由以上两个症状，基本可以确定该应用内存持续上升（内存泄露），是由线程不断创建导致，那具体是哪个线程呢？接下来，我们将该应用的dump文件导出。

## 解决思路
### 1、选择工具，查找线程。
使用MemoryAnalyzerlTool进行分析，将dump文件导入工具，查看线程概况，并查看线程列表，发现前缀为Oss-Thread的线程很多，于是采用Oss进行过滤，过滤出1200多个线程。 

### 2、找到创建线程的对象
那么该线程是由那个对象创建的呢？于是点开线程详情，我们可以看到，该线程是由oss lib包中的OSS类对应的实例创建。

### 3、结合源码分析线程创建原因
在IDE中打开该应用的代码，并打开OSS的源码，果然是该类的问题，该类在执行init()的时候，会创建一个定时任务线程，并会每天执行一次，

### 4、深入查询线程创建原因
继续查询该方法什么时候调用？由于我们是采用反编译拿到的代码，并没有源码，所以我们目前只能通过分析，去定位该方法被那里调用，首先，该类位于oss的lib中，我们用oss是为了上传文件，上传文件之前我们都会有对应的ossService实例，那大概率和该对应有关系，所以沿着这个思路，找到ossService的构造方法。

发现构造过程确实会创建这个类。

### 5、查出元凶
果然在该构造中，有oss类实例化的动作，以及执行init()的动作，至此，基本已经确定是ossService在不断创建导致，那通常我们都是使用spring管理的单例对象，为什么会不断创建ossService对应呢？所以全局检索 new ossService，一看吓一跳。

### 6、分析与优化
#### 分析：
哇，简直了，有同学上传的时候竟然是每上传一次就创建一个ossService实例，并且涉及到好多场景和功能，且没有进行destroy()，就会导致ossService实例越来越多，oss-Thread线程也越来越多，引发内存泄露。

#### 优化：
于是，将所有功能优化，采用spring 管理的ossService实例，优化完毕，上线持续观察，内存和线程基本维持较为平稳。

## 总结
至此，内存泄露问题终于解决，在解决的过程中，还是发现很多我们日常编写代码的不良习惯，比如，拷贝代码，没有做深入思考，直接粘过来使用，至于是否会带来风险以及原有代码是否合理，并没有做过多的评估，导致问题不断放大，最后可能引发线上事故。

ps：

为什么之前一直没有发现这个问题？

因为该内存的增长过程很缓慢，可能需要发布一周左右才能发现，而之前该应用发布频繁，内存还没有爆的时候，应用就被发布了，导致该问题没有被识别到，而最近一段时间，该应用没有发布，所以，问题凸显出来。



> 原文: <https://www.yuque.com/jingdianjichi/xyxdsi/puxcyvwhgd1f1sv6>